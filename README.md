# MyGreenMarketTestExercise
 
1. Возможно ли обойтись в postgres оператором insert при необходимости изменения уже существующих данных?  
- При использовании оператора INSERT можно воспользоваться необязательным предложением ON CONFLICT DO UPDATE, которое задаёт действие, заменяющее возникновение ошибки при нарушении ограничения.

2. Какие проблемы могут возникнуть при параллельном обновлении значений (уровень изоляции «Read Committed»)?  
- В транзакции, работающей на этом уровне, запрос SELECT видит только те данные, которые были зафиксированы до начала запроса; он никогда не увидит незафиксированных данных или изменений, внесённых в процессе выполнения запроса параллельными транзакциями. Однако SELECT видит результаты изменений, внесённых ранее в этой же транзакции, даже если они ещё не зафиксированы. Также стоит отметить, что два последовательных оператора SELECT могут видеть разные данные даже в рамках одной транзакции, если какие-то другие транзакции зафиксируют изменения после запуска первого SELECT, но до запуска второго.

3. Есть древовидная структура, которая хранит в себе информацию о пользователе, его "начальнике", и зарплате. В репозитории хранится 3 файла - скрипт создания таблиц, скрипт заполнения таблицы тестовыми данными, и скрипт расчета сумм зарплат для каждого пользователя(см. далее). Необходимо:  
 - вычислить общую сумму зарплат всех сотрудников. Это просто SELECT SUM(salary) FROM "Users". Не стал выносить в отдельный файл, расписал прям здесь.  
 - вычислить общую сумму полученного вознаграждения по каждому из пользователей с учётом дочерних узлов и оптимизировать расчёт для большого количества пользователей (3000000).
Для начала я хочу уточнить, по моему мнению в данной таблице мы не столкнемся с частыми(условно) вставками и обновлениями. Изменение зарплаты и переход сотрудников из одного отделения в другое - довольна редкая операция.

Я вижу 4 возможных варианта оптимизации данных расчетов.
1) Рассмотреть возможность использования columnStore index. Колоночные индексы рекомендуются использовать при больших объемах данных. Однако каждый раз когда я применял колоночные индексы, ситуация в лучшем случае становилась 50 на 50. При более серьезном подходе к решению данной задаче необходимо будет запускать профилировщик и оценивать результаты при наличии columnStore индекса и классических индексов.
2) Создать материализованный вычисляемый столбец, который будет работать на основе функции вычисления общей зарплаты с учетом дочерних элементов. При таком подходе наши данные будут закешированы и храниться в явном виде напрямую в таблице, а обновляться при каждой вставке или обновлении строки. Результат select к таким данным будет максимально быстрым. Однако такой столбец будет рассчитывать только зарплату для данного пользователя, и обновлять его информацию, но пользователи "выше" не получат обновление информации. Значит необходимо создавать триггер, который будет обновлять родительские записи, что может приводить к большому обходу по таблице.
3) В дополение к предыдущему пункту, можно рассмотреть возможность пометки родительских данных как "грязные", и настроить ежедневную задачу, которая будет перерасчитывать помеченные "грязные" данные.
4) Сделать материализованное представление(я выбрал этот вариант, см. файл в репозитории создание материализованного представления).

(Также возможно стоит посмотреть в сторону использования OLAP, но это только предположение)
